{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph-ISS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Specify  ABSOLUTE paths and create results folder (if not exists already)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "n_threads = 5\n",
    "graph_iss_path = \"\" # Enter absolute path to graph-ISS repository\n",
    "prePro_path = graph_iss_path+\"/prePro_pipeline/\"\n",
    "graph_decoding_path = graph_iss_path+\"/pgm_pipeline/\"\n",
    "\n",
    "dataset_folder = \"\" # Enter absolute path to dataset folder\n",
    "tagList = \"\" # Enter absolute path to tagList\n",
    "\n",
    "results_folder = \"\" # Enter absolute path to execution folder\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create array of intput images\n",
    "The dataset folder should have the following data structure:\n",
    "```\n",
    "dataset_folder\n",
    "├── Base1 (1st imaging round)\n",
    "│   ├── chan0.tif (general stain/anchor channel)\n",
    "│   ├── chan1.tif (nuclei channels/DAPI)\n",
    "│   ├── chan2.tif (T channel)\n",
    "│   ├── chan3.tif (G channel)\n",
    "│   ├── chan4.tif (C channel)\n",
    "│   └── chan5.tif (A channel)\n",
    "├── Base2 (2nd imaging round)\n",
    "│   ├── chan0.tif (general stain/anchor channel)\n",
    "│   ├── chan1.tif (nuclei channels/DAPI)\n",
    "│   ├── chan2.tif (T channel)\n",
    "│   ├── chan3.tif (G channel)\n",
    "│   ├── chan4.tif (C channel)\n",
    "│   └── chan5.tif (A channel)\n",
    "├── Base3 (3rd imaging round)\n",
    "│   ├── chan0.tif (general stain/anchor channel)\n",
    "│   ├── chan1.tif (nuclei channels/DAPI)\n",
    "│   ├── chan2.tif (T channel)\n",
    "│   ├── chan3.tif (G channel)\n",
    "│   ├── chan4.tif (C channel)\n",
    "│   └── chan5.tif (A channel)\n",
    "├── Base4 (4th imaging round)\n",
    "│   ├── chan0.tif (general stain/anchor channel)\n",
    "│   ├── chan1.tif (nuclei channels/DAPI)\n",
    "│   ├── chan2.tif (T channel)\n",
    "│   ├── chan3.tif (G channel)\n",
    "│   ├── chan4.tif (C channel)\n",
    "│   └── chan5.tif (A channel)\n",
    "└── BaseN (n imaging round)\n",
    "    ├── chan0.tif (general stain/anchor channel)\n",
    "    ├── chan1.tif (nuclei channels/DAPI)\n",
    "    ├── chan2.tif (T channel)\n",
    "    ├── chan3.tif (G channel)\n",
    "    ├── chan4.tif (C channel)\n",
    "    └── chan5.tif (A channel)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tif_files = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(dataset_folder):\n",
    "    for file in f:\n",
    "        if '.tif' in file:\n",
    "            tif_files.append(os.path.join(r, file))\n",
    "            \n",
    "tif_files.sort()\n",
    "\n",
    "img_CSV = results_folder+'img_CSV/'\n",
    "# save into file\n",
    "if not os.path.exists(img_CSV):\n",
    "    os.makedirs(img_CSV)\n",
    "    \n",
    "    pd.DataFrame({\"Key\":np.arange(len(tif_files)), \"File\":tif_files}).to_csv(img_CSV+'/out.csv', index=False, header=True, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Estimate normalization values for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" norm.py\n",
    "Compute normalization intervals for each channel and round.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sys.argv[1] : input csv file contaning an array of input images\n",
    "    sys.argv[2] : upper percentile value of 98th percentile distri-\n",
    "        bution of image patches for signal level estimation.\n",
    "    sys.argv[3] : number of running threads. Each thread run over \n",
    "        an image.\n",
    "    sys.argv[4] : output csv file where to store computed intervals\n",
    "    sys.argv[5] : number of random patches used to estimate norma-\n",
    "        lization intervals\n",
    "\"\"\"\n",
    "\n",
    "norm_folder = results_folder+\"norm/\"\n",
    "\n",
    "if not os.path.exists(norm_folder):\n",
    "    os.makedirs(norm_folder)\n",
    "\n",
    "    %run $prePro_path'/norm.py' $img_CSV'/out.csv' 99 $n_threads $norm_folder'/out.h5' 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Register whole slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" mainReg.py\n",
    "Course registration.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sys.argv[1] : Path to pre-processing library\n",
    "    sys.argv[2] : Output folder where to store aligned images\n",
    "    sys.argv[3] : Input csv file contaning an array of input images\n",
    "    sys.argv[4] : Number of resolution levels used for registration\n",
    "    sys.argv[5] : Type of registration (valid arguments: \"translati-\n",
    "        on\", \"rigid\", or \"affine\")\n",
    "    sys.argv[6] : String flag that enables sequencing rounds registra-\n",
    "        tion using maximum projected images of general stain and\n",
    "        nuclei channel if enabled. Genaral stain images only are used\n",
    "        if disabled. (valid arguments: \"Nuclei\": feature enabled,\n",
    "        other string: feature disabled)\n",
    "    sys.argv[7] : Type of registration procedure. (valid arguments:\n",
    "        \"DO1\" : if only the general stain of the first sequencing round\n",
    "        is available\n",
    "        \"DO\" : if a general stain image is available for each sequencing\n",
    "        round\n",
    "    sys.argv[8] : highest resolution level for multiresolution image reg-\n",
    "        istration\n",
    "    sys.argv[9] : lower resolution level for multiresolution image regi-\n",
    "        stration\n",
    "    sys.argv[10] : flag to enable BSpline registration after rigid\n",
    "\"\"\"\n",
    "\n",
    "registration_folder = results_folder+\"registration/\"\n",
    "\n",
    "if not os.path.exists(registration_folder):\n",
    "    os.makedirs(registration_folder)\n",
    "    os.makedirs(registration_folder+'/folder1')\n",
    "\n",
    "    %run $prePro_path'/mainReg.py' $prePro_path $registration_folder'/folder1' $img_CSV'/out.csv' 5 'rigid' 'Nuclei' 'DO' 512 8 'noBspline'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Image tiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tile_size_x = 1024\n",
    "tile_size_y = 1024\n",
    "\n",
    "alltiles = results_folder + \"alltiles/\"\n",
    "register_tiles = alltiles + \"registered/\"\n",
    "if not os.path.exists(alltiles):\n",
    "    os.makedirs(alltiles)\n",
    "    if not os.path.exists(register_tiles):\n",
    "        os.makedirs(register_tiles)\n",
    "    \n",
    "        for reg_tif in os.listdir(registration_folder+'/folder1'):\n",
    "            reg_tif_name = os.path.splitext(reg_tif)[0]\n",
    "            os.makedirs(register_tiles+reg_tif_name)\n",
    "            # Run bioformat command line tool bfconvert\n",
    "            !bfconvert -tilex $tile_size_x -tiley $tile_size_y $registration_folder'/folder1/'$reg_tif $register_tiles$reg_tif_name/%x_%y.tif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Tiles processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd    \n",
    "\n",
    "for tile_tif in  os.listdir(register_tiles+os.listdir(register_tiles)[0]):\n",
    "    tile = os.path.splitext(tile_tif)[0]\n",
    "    # Collect tile channels and rounds\n",
    "    if not os.path.exists(alltiles+tile):\n",
    "        os.makedirs(alltiles+tile)\n",
    "        tifs = glob.glob(register_tiles+'/*/'+tile_tif)\n",
    "        pd.DataFrame({'Key':[tile]*len(tifs), \"File\":tifs}).to_csv(alltiles+tile+'/out.csv', index=False, header=True, sep='\\t')\n",
    "            \n",
    "        \n",
    "    # Run pre-processing\n",
    "    prePro_folder = results_folder+tile+'_prePro/'\n",
    "    if not os.path.exists(prePro_folder):\n",
    "        os.makedirs(prePro_folder)\n",
    "        os.makedirs(prePro_folder+\"/folder1\")\n",
    "        \n",
    "        \"\"\" main.py\n",
    "            Performs tile registration, tile normalization using\n",
    "            precomputed values, tophat filtering, signal candida\n",
    "            -te detection and signal merging.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            sys.argv[1] : Path to pre-processing library\n",
    "            sys.argv[2] : Input csv file contaning an array of in-\n",
    "                put images\n",
    "            sys.argv[3] : Output folder where to store aligned im-\n",
    "                ages\n",
    "            sys.argv[4] : Output dataframe of signal candidate dete-\n",
    "                ction after merging\n",
    "            sys.argv[5] : Output dataframe of signal candidate dete-\n",
    "                ction before merging\n",
    "            sys.argv[6] : Number of thread used for parallelizing\n",
    "                sequencing rounds\n",
    "            sys.argv[7] : h maxima threshold\n",
    "            sys.argv[8] : csv file containing image normalization\n",
    "                intervals\n",
    "            sys.argv[9] : Output hdf5 object storing normalized im-\n",
    "                ages\n",
    "            sys.argv[10] : Output hdf5 object storing signal candi-\n",
    "                dates binary masks\n",
    "            sys.argv[11] : Type of registration procedure. (valid\n",
    "                arguments: \"DO1\" : if only the general stain of\n",
    "                the first sequencing round is available, \"DO\" : if\n",
    "                a general stain image is available for each sequen-\n",
    "                cing round\n",
    "        \"\"\"\n",
    "        tile_path = alltiles+tile+'/out.csv'\n",
    "        %run $prePro_path'/main.py' $prePro_path $tile_path $prePro_folder\"/folder1\" $prePro_folder\"/out1\" $prePro_folder\"/out2\" $n_threads 0.05 $norm_folder'/out.h5' $prePro_folder\"/out3\" $prePro_folder\"/candidates_max.h5\" \"DO\"\n",
    "    \n",
    "    # Predict probabilities of signal candidate detections\n",
    "    predProb_folder = results_folder+tile+'_predProb/'\n",
    "    if not os.path.exists(predProb_folder):\n",
    "        os.makedirs(predProb_folder)\n",
    "        \n",
    "        \"\"\" get_proba_DNN.py\n",
    "            Signal candidate probability predictions.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            sys.argv[1] : Path to signal probability prediction library\n",
    "            sys.argv[2] : Input dataframe of signal candidate detection\n",
    "                after merging\n",
    "            sys.argv[3] : Output dataframe of signal probability predictions\n",
    "            sys.argv[4] : (Optional) probability threshold for signal candid-\n",
    "                    date predictions\n",
    "        \"\"\"\n",
    "        try:\n",
    "            %run $prePro_path'/network/get_proba_DNN.py' $prePro_path'/network' $prePro_folder\"/out1\" $predProb_folder\"/out1\"\n",
    "        except:\n",
    "            print(\"[ERROR] \"+ tile+ \" \" + sys.exc_info()[0])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Graph-based decoding\n",
    "    GM_folder = results_folder+tile+'_GM/'\n",
    "    if not os.path.exists(GM_folder):\n",
    "        os.makedirs(GM_folder)\n",
    "\n",
    "        \"\"\" main.py\n",
    "            Graph-based decoding of signal candidates.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            sys.argv[1] : Path to decoding library\n",
    "            sys.argv[2] : Dataframe of signal probability predictions\n",
    "            sys.argv[3] : Output file stroring dataframe of decoded\n",
    "                barcodes\n",
    "            sys.argv[4] : Output csv file of decoded barcodes\n",
    "            sys.argv[5] : Number of threads for parallelization\n",
    "            sys.argv[6] : d_th parameter for building graph connected\n",
    "                components\n",
    "            sys.argv[7] : d_max parameter for building graph connected\n",
    "                components\n",
    "            sys.argv[8] : Output list of sets of signals detections contribu-\n",
    "                ting to decoded barcodes\n",
    "            sys.argv[9] : enable barcodes decoding guided by the list\n",
    "                of targeted barcodes (valid arguments, \"prior\": feature\n",
    "                enabled, other string: feature disabled)\n",
    "            sys.argv[10] : csv file of targeted barcode sequences\n",
    "            sys.argv[11] : Dataframe of signal candidate detection befo-\n",
    "                re merging\n",
    "            sys.argv[12] : hdf5 object storing normalized images\n",
    "            sys.argv[13] : Path to signal probability prediction library\n",
    "        \"\"\"\n",
    "        try:\n",
    "            %run $graph_decoding_path'/main.py' $graph_decoding_path $predProb_folder\"/out1\" $GM_folder'/out2' $GM_folder'/out1' $n_threads 3 4 $GM_folder'/out3' blind $tagList $prePro_folder\"/out2\" $prePro_folder\"/out3\" $prePro_path'/network'\n",
    "        except:\n",
    "            print(\"[ERROR] \"+ tile+ \" \" + sys.exc_info()[0])\n",
    "        \n",
    "        \n",
    "    # Add tile offset to decoded barcode coordinates\n",
    "    barcodes_folder = results_folder+'/barcodes/'\n",
    "    if not os.path.exists(barcodes_folder):\n",
    "        os.makedirs(barcodes_folder)\n",
    "\n",
    "        df = pd.read_csv(GM_folder+'/out1')\n",
    "        x, y = tile.split('_')\n",
    "        df.loc[:,'global_X_pos'] = df.loc[:,'global_X_pos'] + x * tile_size_x\n",
    "        df.loc[:,'global_Y_pos'] = df.loc[:,'global_Y_pos'] + y * tile_size_y\n",
    "        df.to_csv(barcodes_folder+tile+'_barcodes_withOffset.csv', index=False, header=True, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Output file (barcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate result in a single file\n",
    "for i, tile_barcodes in enumerate(os.listdir(os.listdir(barcodes_folder)[0])):\n",
    "    if i==0:\n",
    "        barcodes_df = pd.read_csv(barcodes_folder+tile_barcodes)\n",
    "    else:\n",
    "        df = pd.read_csv(barcodes_folder+tile_barcodescodes)\n",
    "        barcodes_df = pd.concat([barcodes_df, df])\n",
    "\n",
    "# Decoded barcode list        \n",
    "barcodes_df.toresults_folderlts_folderlts_folder(results_folder+'/barcodes.csv', index=False, header=True, sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
